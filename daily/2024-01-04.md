## 改进 Embedding 效果

[Improving Text Embeddings with Large Language Models](https://arxiv.org/pdf/2401.00368.pdf)

论文试图解决的问题：
- 提高文本嵌入（text embeddings）的质量，特别是在使用合成数据和少量训练步骤的情况下。
- 克服现有方法依赖于多阶段中间预训练和手动收集数据的局限性，这些数据通常受限于任务多样性和语言覆盖范围。

相关研究：
- 早期的文本嵌入方法，如潜在语义索引（LSI）和词嵌入的加权平均。
- 利用自然语言推理（NLI）数据集对BERT进行微调以学习文本嵌入的方法，如Sentence-BERT和SimCSE。
- 通过对比损失在大量弱监督文本对上进行预训练，然后在少量标记数据集上进行微调的方法，如E5和BGE。

论文如何解决这个问题：
- 提出了一种新方法，利用专有的大型语言模型（LLMs）生成多样化的合成数据，覆盖近100种语言的数十万文本嵌入任务。
- 使用两步提示策略，首先让LLMs生成候选任务池，然后根据给定任务从池中生成数据。
- 对于文本嵌入模型，选择微调强大的开源LLMs，而不是小型BERT风格的模型。
- 在合成数据上使用标准的对比损失进行微调。

论文做了哪些实验：
- 生成了500k个示例，其中150k个唯一的指令，覆盖93种语言。
- 在MTEB基准测试上评估了训练模型，包括使用合成数据和混合合成数据与标记数据的设置。
- 对比了无监督模型和有监督模型的性能。
- 在MIRACL数据集上评估了模型的多语言检索能力。
- 引入了一个新的合成任务——个性化密码检索，以评估模型在长上下文中的能力。

可以进一步探索的点：
- 提高模型在低资源语言上的多语言性能。
- 使用开源LLMs生成合成数据。
- 研究如何通过轻量级后训练（post-training）高效地适应更长的上下文。
- 探索提高LLM基础文本嵌入的推理效率和降低存储成本的方法。

总结论文的主要内容：
- 本文介绍了一种新方法，通过使用合成数据和少量训练步骤来提高文本嵌入的质量。
- 通过利用专有的大型语言模型生成多样化的合成数据，覆盖多种语言和任务。
- 在MTEB基准测试上，该方法在没有使用任何标记数据的情况下取得了强大的性能，并在微调合成数据和标记数据的混合时，取得了新的最先进结果。
- 实验表明，该方法在多语言检索能力上表现良好，尤其是在资源丰富的语言上，但在低资源语言上仍有改进空间。
- 论文还讨论了对比预训练的必要性，并展示了模型在长上下文中的能力，以及训练超参数的分析。

## 基于 PDF 文件直接进行问答

[PDFTriage: Question Answering over Long, Structured Documents](https://arxiv.org/pdf/2309.08872.pdf)

[Github](https://github.com/HAMNET-AI/PDFTriage)

[Blog](https://hamnet.ai/work/pdf-extract)

[API](https://apifox.com/apidoc/shared-a55f1a3d-4871-41b7-8f1a-3af83807410b/api-120356017)

### 这篇论文试图解决什么问题？

- **结构化文档处理问题**：论文指出，现有的大型语言模型（LLMs）在处理结构化文档（如网页、PDF、演示文稿等）时存在问题。这些文档通常包含丰富的结构，如不同的页面、表格、章节等，而将这些文档表示为纯文本与用户的心智模型不符，导致一些看似简单的问题在现有的文档问答（QA）方法中无法得到正确解答。

### 有哪些相关研究？

- **工具增强的LLMs**：研究者们利用自监督技术教会模型使用工具，通过少量示例来引导模型执行API调用。
- **检索增强的LLMs**：通过外部知识源增强LLMs的推理能力，使用外部文档检索来提供相关信息。
- **文档理解**：专注于文档结构和内容的问答任务，如DocVQA和DUDE数据集，以及QASPER数据集，这些数据集专注于从研究论文中提取信息。

### 论文如何解决这个问题？

- **PDFTriage方法**：提出了一种新的方法，允许模型根据结构或内容检索上下文。通过提供文档结构的元数据和一系列模型可调用的检索函数，如`fetch_pages`、`fetch_sections`等，来增强模型对结构化文档的理解和问答能力。

### 论文做了哪些实验？

- **构建数据集**：构建了一个包含900多个人类生成的问题的数据集，覆盖10种不同类别的问题类型，用于评估PDFTriage方法。
- **模型对比**：使用PDFTriage方法与现有的基于页面检索和基于块检索的方法进行对比。
- **人类评估**：通过人类标注者对生成的答案进行评估，以衡量不同方法在回答质量、准确性、可读性和清晰度等方面的性能。

### 有什么可以进一步探索的点？

- **多模态方法**：将表格和图形信息整合到GPT-4的问答系统中。
- **问题类型整合**：将问题类型考虑进PDFTriage方法中，以提高方法的效率和效果。

### 总结一下论文的主要内容？

- **问题识别**：论文识别了当前LLMs在处理结构化文档问答时的局限性，即将文档视为纯文本而非结构化对象。
- **数据集发布**：为了促进对此问题的研究，论文发布了一个包含标记问题类型的数据集，以及模型响应。
- **PDFTriage方法**：提出了一种新的方法，通过结构化文档元数据和模型可调用的检索函数来增强LLMs对结构化文档的问答能力。
- **实验结果**：PDFTriage方法在多个问题类别中表现出色，优于现有的检索增强LLMs。
- **未来方向**：论文提出了未来工作的潜在方向，包括开发多模态方法和整合问题类型。

### 详细说说 PDFTriage 方法, 都有哪些步骤

PDFTriage 方法是一个专门针对结构化文档的问答系统，它通过利用文档的结构信息来提高问题回答的准确性和效率。这个方法包括以下几个主要步骤：

1. **生成文档元数据**：
   - 首先，PDFTriage 生成一个结构化的文档元数据表示，这包括提取文档的结构元素，如页面、章节、标题、表格和图标题等，并将其转换为可读的元数据。
   - 这些元数据以JSON格式表示，包含了文档中各个部分的详细信息，如页码、位置等。

2. **基于LLM的分诊（Triage）**：
   - 给定一个问题后，PDFTriage 会查询大型语言模型（LLM），以选择文档中需要用于回答问题的精确内容（页面、章节、检索内容等）。
   - 这一步骤涉及到使用一系列模型可调用的检索函数，如 `fetch_pages`（获取指定页面的文本）、`fetch_sections`（获取指定章节的文本）、`fetch_figure`（获取指定图标题的文本）、`fetch_table`（获取指定表格标题的文本）和 `retrieve`（基于自然语言查询文档并获取相关片段）。

3. **使用检索到的内容回答问题**：
   - 根据问题和检索到的内容，PDFTriage 生成一个答案。
   - 在这个步骤中，模型会根据检索到的上下文信息来生成对问题的解答。

PDFTriage 方法的关键创新在于它能够直接与文档的结构进行交互，而不是仅仅依赖于文档的纯文本内容。这种方法允许模型更精确地定位到文档中与问题相关的关键部分，从而提高了问答系统的性能。通过这种方式，PDFTriage 能够处理需要跨多个页面或文档结构部分的复杂问题，这是传统的基于纯文本的问答系统难以做到的。

---

### web crawler

[news-please](https://github.com/fhamborg/news-please)

看起来是一个从现在爬取内容的项目, 亮点是会对爬取的内容进行**结构化**, 返回的是一个 json. 一个结果的例子: [sample](https://github.com/fhamborg/news-please/blob/master/newsplease/examples/sample.json).

---

### pdf 解析效果评价方法

[gipplab/pdf-benchmark](https://github.com/gipplab/pdf-benchmark)

提供了一种 pdf 解析效果评价方法.

一个标注好的数据集: [DocBank](https://doc-analysis.github.io/docbank-page/index.html). 上面的 repo 就是在这个数据集上构建出来的.

数据集是对 line 级别进行的标注, 每个样本 line 包含:

- bounding box ((x0, y0), (x1, y1)) - > (x0, y0, x1, y1)
- color (R, G, B)
- font
- label

格式为:

Index	0	1	2	3	4	5	6	7	8	9
Content	token	x0	y0	x1	y1	R	G	B	font name	label

这里的 label 有:

Abstract	Author	Caption	Equation	Figure	Footer	List	Paragraph	Reference	Section	Table	Title

评价的整体逻辑为: [Evaluation Framework](https://github.com/gipplab/pdf-benchmark/blob/main/doc/documentation.md)

其中的 **Assemble Data** 模块可以研究下, 看看是怎么将最碎片化的 line 组合为块的.

---

### 开发经验: Google 的 API 出入参风格指南

[JSON风格指南](https://github.com/darcyliu/google-styleguide/blob/master/JSONStyleGuide.md)

---
