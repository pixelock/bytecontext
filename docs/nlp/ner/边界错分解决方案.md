# 实体边界错分

NER 任务中常出现实体边界错分的情况. 例如识别出的实体 span 中包含真正的实体, 但还包含多余的 chars.

例如识别菜品实体, `这家饭店的爆品是火锅食物` 这句话中对应的菜品实体为 `火锅`, 但模型可能会把 `火锅食物` 识别成一个实体.

又比如 `这家饭店的爆品是煲仔饭和椰子鸡`, 模型可能会把 `煲仔饭和椰子鸡` 识别成一个整体, 但实际上应该是两个实体.

# 优化方法

## 数据角度

### 边界噪声挖掘

从 badcase feedback 解决实际问题的角度, 模型训练后的推理有错误边界的情况, 可以根据标签, 对边界错分的实体, 统计出其中的高频噪音词(例如上面`这家饭店的爆品是火锅食物`这一例中的`食物`), 将这些易错的高频噪音, 随机添加到训练数据集中实体的边界处.

或者从训练集中, 挖掘与易错实体相关的噪声词, 把这些词插入到边界处. 例如以`火锅`进行展开, 利用 `N-gram` 搜索实体附近的词语, 比如说找到了`辣椒`, 就可以构建`这家饭店的爆品是火锅辣椒`这条样本.

# 损失函数

如果使用 token classification 这种形式做 NER 任务, 样本中大部分 token 的标签都是 `O(other)`, 表现为标签极其不平衡.

使用 **Focal loss** 这类应对标签不平衡的分类损失函数, 使得 `O` 类标签分错的代价更大一些.

一个猜想, GlobalPointer 做 NER 任务使用的 [ZLPR loss](https://kexue.fm/archives/7359), 解决了标签不平衡的问题, 是不是使用 GlobalPointer 对于边界的把控, 比 token classification 方案更好一些? 需要实验验证.
