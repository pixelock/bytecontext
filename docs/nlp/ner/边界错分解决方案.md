# 实体边界错分

NER 任务中常出现实体边界错分的情况. 错分可以分为两种大类:

- 多预测: 识别出的实体 span 中包含真正的实体, 但还包含多余的 chars
- 少预测: 模型识别的实体短了, 需要补全

例如识别菜品实体, `这家饭店的爆品是火锅食物` 这句话中对应的菜品实体为 `火锅`, 但模型可能会把 `火锅食物` 识别成一个实体.

又比如 `这家饭店的爆品是煲仔饭和椰子鸡`, 模型可能会把 `煲仔饭和椰子鸡` 识别成一个整体, 但实际上应该是两个实体.

# 优化方法

## 数据角度

### 边界噪声挖掘

从 badcase feedback 解决实际问题的角度, 模型训练后的推理有错误边界的情况, 可以根据标签, 对边界错分的实体, 统计出其中的高频噪音词(例如上面`这家饭店的爆品是火锅食物`这一例中的`食物`), 将这些易错的高频噪音, 随机添加到训练数据集中实体的边界处.

或者从训练集中, 挖掘与易错实体相关的噪声词, 把这些词插入到边界处. 例如以`火锅`进行展开, 利用 `N-gram` 搜索实体附近的词语, 比如说找到了`辣椒`, 就可以构建`这家饭店的爆品是火锅辣椒`这条样本.

# 损失函数

如果使用 token classification 这种形式做 NER 任务, 样本中大部分 token 的标签都是 `O(other)`, 表现为标签极其不平衡.

使用 **Focal loss** 这类应对标签不平衡的分类损失函数, 使得 `O` 类标签分错的代价更大一些.

一个猜想, GlobalPointer 做 NER 任务使用的 [ZLPR loss](https://kexue.fm/archives/7359), 解决了标签不平衡的问题, 是不是使用 GlobalPointer 对于边界的把控, 比 token classification 方案更好一些? 需要实验验证.

# Pipeline

## 实体边界识别 + 实体类型分类

如果业务对边界的准确性特别敏感. 可以使用两阶段来解决 NER 问题.

- 第一阶段, 先确定实体 span 边界
- 第二阶段再对 span 进行分类, 确定实体的类别

第一阶段, 使用 **SPAN 排列** 的方式, 往往能取得更好的效果.

![](/resources/images/nlp/span-1.webp)

## NER + 实体边界重定向模型

[NER上分利器：实体边界重定位](https://bbruceyuan.com/post/17.html)

![](/resources/images/nlp/ner-1.png)

在 [Don’t Eclipse Your Arts Due to Small Discrepancies: Boundary Repositioning with a Pointer Network for Aspect Extraction](https://aclanthology.org/2020.acl-main.339/) 论文中, 提出了对 NER 模型的结果, 通过构建新的模型, 进行边界重定向的方法论.

例如 `他爱吃苹果派。` 这个句子中, 对应的实体是 `苹果派`, 但模型识别出的是 `苹果`.

边界重定向模型使用的输入数据样式如上图, `[CLS] sentence1 [SEP] sentence2 [SEP]`:

- sentence1 是第一步的 NER 模型预测得到的结果
- sentence2 是原来的输入句子

将句子中, 每个预测正确和错误的实体, 都与原句子拼接在一起构建训练样本. 假设步骤一中一共输出了两个实体, 那么我们就构建两个训练样本.

样本的输出如同 NER 一样, 是在补充了 sentence1 信息之后, 预测 sentence2 中实体.

如何获得 sentence1 是关键.

sentence1 代表的是候选实体, 候选实体的正样本, 是将正确的实体直接与句子拼接生成即可. 负样本通过步骤一的模型产生, 具体做法是, 生成一个字典, **当真实的实体当做 key, value 是一个负样本列表.**

```python
{
    'true entity': ['wrong entity1', 'wrong entiry2']
}
```

每一个真实的实体都对应一个负样本列表, 把**每一个训练的 epoch 中产生的 wrong entity 都加入到对应的 true entity 里面**. wrong entiry 应该和 true entity 有重合.

比如`苹果`和`苹果派`之间有重合, 而`爱吃`和`苹果派`之间没有重合，因此`苹果`应该当做训练样例, 而`爱吃`不应该当做负的训练样例.

在推理阶段, 第一步将句子预测出候选实体, 然后对候选实体拼接原句子, 送入到重定向模型中, 确定最终的实体边界.

# 后处理

## 最大匹配补全

[深度学习时代，分词算法的真实应用实例](https://bbruceyuan.com/post/2.html)

`xxxxxx, 京东方科技集团昨日发表简，xxxxx` 对应的实体为 `京东方科技集团`. 如果识别出来的是 `东方科技集团`, 需要进行补全.

首先我们需要构建一个词表, 词表中包含了所有的实体, 可以根据业务积累, 也可以通过训练集收集. 然后通过**前向最大匹配问题**, 从词表中进行匹配, 补齐.

这样补齐的内容可能过长或者还是没有补够, 可以通过再构建一个前后缀词典进行补齐结果的置信校验. 前后缀词典, 是在训练集中实体的基础上, 统计实体的高频前缀词和后缀词(或 N-gram), 如果上面补全的内容, 在前后缀词表中, 在高频保证的前提下, 可以任务是通过了置信度校验.
