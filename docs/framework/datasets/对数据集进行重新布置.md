# Rearranging dataset

重新布置数据集, 指的是对数据集进行筛选样本, 划分数据集(创建 splits), 将大数据集分片等操作, 不会影响每一条样本中的内容. 接下来介绍一些常用的方法.

## Shuffle

### Dataset.shuffle()

**Dataset** 进行 `Dataset.shuffle()` 操作, 会在整个数据集上进行 shuffle. 它的原理是对 `[0, 1, 2, ... len(my_dataset) - 1]` 索引列表进行 shuffle, 然后在获取数据时, 先取打乱后的索引, 然后根据索引获取到相应的数据.

```python
my_dataset = my_dataset.shuffle(seed=42)
print(my_dataset[0])
```

实际上, shuffle 操作创建了一个 `indices mapping` 来完成上面的逻辑. 但是, 一旦一个数据集有了 `indices mapping`, 在这个数据集上的其他操作可能会慢10倍, 一个原因是因为拿数据的过程多了一个获取样本行的 index 步骤; 另外一个影响更大的原因是, 这种读取方式破坏了从连续的 chunk 中读取数据的高效性.

为了在 shuffle 之后的处理速度能够恢复的之前的程度, 需要将整个数据集在磁盘上重写一遍, 使打乱后的数据重新形成一块连续的 chunks, 并同时抛弃掉了 `indices mapping`.

```python
new_dataset = my_dataset.flatten_indices()
```

另外还有一种方法可以避免 shuffle 后效率的损失: 将 Dataset 转换为 IterableDataset, 然后使用 IterableDataset 的 shuffle 逻辑. 避免了对操作对全局样本应用, 而只是对 buffer 内的样本进行 shuffle.

```python
iterable_dataset = dataset.to_iterable_dataset(num_shards=128)
shuffled_iterable_dataset = iterable_dataset.shuffle(seed=42, buffer_size=1000)
```

### IterableDataset.shuffle()

**IterableDataset** 由于 lazy 机制, 无法提前获取到具体的样本, 也无法在文件中随机地获取样本, 因此无法使用与 `Dataset` 一样的方法对数据进行 shuffle. 所以 IterableDataset 无法对全部数据进行全局的 shuffle. `IterableDataset.shuffle()` 实现的是一种快速近似 shuffle, 通过维护一个 buffer 记录一定容量的样本, 然后在迭代过程中, 随机地从 buffer 中采样数据样本输出. 在使用 `shuffle()` 时, 需要指定 `buffer_size`, 默认为 1000:

```python
my_iterable_dataset = my_iterable_dataset.shuffle(seed=42, buffer_size=100)
for example in my_iterable_dataset:
    print(example)
    break
```

如果数据集是由多个文件组成, 这里每个文件中的数据对应着一个 **`shard`**. `IterableDataset.shuffle()` 还对 `shard` 维度进行 shuffle, 即 shuffle 后读取的前两条数据可能来自不同的文件.

## Sort

与打乱对应的就是排序. 根据指定列中不同样本对应的值得大小进行排序.

```python
dataset["label"][:10]
# [1, 0, 1, 0, 1, 1, 0, 1, 0, 0]
sorted_dataset = dataset.sort("label")
sorted_dataset["label"][:10]
# [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
sorted_dataset["label"][-10:]
# [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
```

与 shuffle 类似, sort 也会创建 `indices mapping`, 而不是真正地改变底层数据. 后续找指定行的数据时, 再根据 `indices mapping` 找到对应行的 index.

## Select 切片

`select()` 会根据指定的索引, 切分出一个子数据集, 返回的也是一个 `Dataset` 对象.

```python
from datasets import load_dataset
ds = load_dataset("rotten_tomatoes", split="validation")
ds.select(range(4))
```

```python
Dataset({
    features: ['text', 'label'],
    num_rows: 4
})
```

与直接使用 `dataset[:k]` 不同的是, 后者直接切片返回的是字典, key 为数据集中的列, value 为每列的前 k 个值.

```python
from datasets import load_dataset

dataset = load_dataset('fka/awesome-chatgpt-prompts')
sub = dataset['train'][:2]
print(sub)
```

```python
{
    'act': [
        'Linux Terminal',
        'English Translator and Improver'
    ],
    'prompt': [
        'I want you to act as a linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. when i need to tell you something in english, i will do so by putting text inside curly brackets {like this}. my first command is pwd',
        'I want you to act as an English translator, spelling corrector and improver. I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in English. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level English words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. My first sentence is "istanbulu cok seviyom burada olmak cok guzel"'
    ]
}
```

## Filter

对行维度(样本)进行过滤, 满足符合要求的样本. 我们需要构造一个接受一条样本作为输入的函数, 根据样本中的信息判断是否采用这条样本.

```python
start_with_ar = dataset.filter(lambda example: example["sentence1"].startswith("Ar"))
len(start_with_ar)
start_with_ar["sentence1"]
```

另外, 还可以将样本的**索引**也考虑进来, 通过设置参数 `with_indices = True`.

```python
even_dataset = dataset.filter(lambda example, idx: idx % 2 == 0, with_indices=True)
len(even_dataset)
# 1834
len(dataset) / 2
# 1834.0
```

这个技巧在奇数/偶数索引代表不同类型的样本(例如0为问题, 1为答案)的情景中会用到.

## Split

---

# 参考资料

- [Process](https://huggingface.co/docs/datasets/main/en/process#process)
