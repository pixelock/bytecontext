# 什么是广播机制

**广播**(broadcast)一词是用来描述如何在**形状不一的张量**上应用算术运算. 在满足特定限制的前提下, **shape维度较小的张量** *广播至* **shape维度较大的张量**, 使得两者形状互相兼容, 从而可以进行计算.

广播机制还有一些特性:

- 广播发生在C层面, 而不是Python层面
- 广播可以避免不必要的数据复制, 是高效的算法实现

# 广播机制的发生条件

- 每个张量都至少有一个维度
- 对两个张量的维度从后往前遍历, 遍历每个维度的过程中, 两个维度的大小必须满足:
  - 相等
  - 其中一个张量的维度尺寸为`1`
  - 其中一个张量不存在这个维度

满足上面条件的两个张量发生计算时, 就会发生广播机制. 用具体的例子体现:

**相同形状的张量总是可广播的**

```python
x = torch.empty(5, 7, 3)
y = torch.empty(5, 7, 3)
```

**维度缺失 / 维度长度为1**

- 倒数第一个维度: 两者的尺寸均为`1`
- 倒数第二个维度: 张量`n`的尺寸为`1`
- 倒数第三个维度: 两者尺寸相同
- 倒数第四个维度: 张量`n`的该维度不存在

```python
m = torch.empty(5, 3, 4, 1)
n = torch.empty(   3, 1, 1)
```

**维度不等(且不为1)不可广播**

```python
p = torch.empty(5, 2, 4, 1)
q = torch.empty(   3, 1, 1)
```

# 广播后张量的维度

如果两个张量可以发生广播, 那么广播后的张量尺寸按照如下方法计算:

- 如果`x`和`y`的维度数量不同, 对维度数量少的张量增加新的维度, 且维度大小为1, 使得两个张量的维度数量相同
- 对长度为1的维度, 结果的维度大小是另一个张量对应维度的大小

例如:

```python
c = torch.empty(5, 1, 4, 1)
d = torch.empty(   3, 1, 1)
(c + d).size()  # torch.Size([5, 3, 4, 1])

f = torch.empty(      1)
g = torch.empty(3, 1, 7)
(f + g).size()  # torch.Size([3, 1, 7])
```

# 参考资料

- [BROADCASTING SEMANTICS](https://pytorch.org/docs/stable/notes/broadcasting.html)
- [torch的广播机制(broadcast mechanism)](https://zhuanlan.zhihu.com/p/86997775)
