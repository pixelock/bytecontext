# RAG 检索召回方案总览

## 意图识别

- 根据意图, 制定计划, 拆分为若干步骤, 在每个步骤选择合适的工具进行处理
- 规划生成的单个步骤, 做好抽象和封装, 明确输入和输出以及执行逻辑
- 根据每个步骤返回的结果, 动态决定下一步的方案

## 多路召回

在一个系统中, 使用多种召回方案, 从不同的索引中召回. 常见的召回方法有:

- 使用 query embedding, 对文档切块后的文本 embedding 进行召回
- 使用 BM25 等文本相似度计算的方法, 对文档切块后的文本进行召回
- 使用关键词匹配, 召回包含关键词的文档
- 使用关键词的 embedding, 召回相关的关键词, 再召回这些相关关键词对应的文档
  - 或者设计 prompt, 通过训练语义模型, 直接使用关键词的 embedding 召回文档

## 召回内容排序

多路召回的内容, 与 query 的贴切程度 / 重要程度不同, 需要进行排序, 进行截断, 或者按照一定的顺序在 prompt 中排列.

# 检索召回方案汇总

## 意图识别 / 问题理解

通过解析用户问题, 准确识别用户意图后, 才能更好的规划后续处理步骤, 这是问答系统的基础.

### HyDE

[Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496) 一文提出了 **Hypothetical Document Embeddings** 方法.

使用基础模型(LLMs)在训练过程中已经掌握的相关语料, 面向用户问题(Query), 使用大模型直接回答, 生成虚构的文档. 该文档不会作为最后的回答, 而是借助 LLM 对问题的理解能力, 生成与 Query 相关的内容. 这相当于自动化生成相关性标签.

虚构文档生成后, 对文档进行 embedding, 然后在本地知识库中进行相似性检索, 寻找相关的文档.

![](/resources/images/llm/rag-3.png)

HyDE 要求与用户问题相关的知识已经存在于 LLM 基础模型中. 但专业领域知识, 可能本来就是未公开的, LLM 不会学习到相关的知识. 此时 LLM 生成的虚构文档, 可能包含很多噪音, 所以效果不一定很明显.

另外生成文档的额外交互, 进一步增加了时间开销.

在 Langchain 中提供了 [HyDE Chain](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb) 的实现.

### 意图类别分类 + 槽位填充

**在为用户提供服务的预设场景下**, 细分用户各种意图的类别, 定制对应的语义槽, 每个槽位可以视为在语义层面体现意图的基本单位.

通过任务模型, 或者 LLMs 理解用户问题提取语义槽中需要的内容. 使用 LLM, 通过构建 Prompt 引导模型输出. Prompt 中的 System Role 告知 LLM 需要提取槽位信息, LLM 通过多轮对话引导用户给出所有槽位信息.

例如游戏攻略场景中, 一类意图为`球员打法`, 那么必须提供: 球员姓名, 年代(比如2020/2022年), 比赛模式的信息.

```
"球员打法" : {
    "球员名称" : ____,
    "年代" : ____,
    "比赛模式": ____,
}
```
