文本切分的策略和选用的语义向量模型息息相关, 例如:

- 切分的文本长度, 不能超过语义向量模型限制的输入长度. 例如使用 BERT 模型, 长度不能超过 512 - 2 (两个 special token)

# 滑动窗口切分

把文档分成**有重叠**的若干段, 可以看做是在原始文本上通过滑动窗口, 框选出多个文本片段, 然后将每一段文本片段都丢给语义向量模型, 转化为语义向量, 并进行索引.

在 `langchain` 中, 可以使用 `RecursiveCharacterTextSplitter` 文本切分类来实现, 这种切分方法, 对中文相比较友好一些. 原理是先使用分隔符对原始文本进行分割(默认为 `["\n\n", "\n", " ", ""]`), 然后对分割后的文本进行递归切分, 直到将要拼接的内容, 在拼接后的长度超过 `chunk_size` 阈值位置.

使用时, 重叠的长度和窗口长度需要根据实际进行调整.

参考: [Understanding LangChain's RecursiveCharacterTextSplitter](https://dev.to/eteimz/understanding-langchains-recursivecharactertextsplitter-2846)

# 借助 BERT 的 NSP 任务切分

BERT 中的 NSP 任务, 即 Next Sentence Prediction 任务, 预测的是两个句子是否是连续的. 预训练准备语料时, 从语料库中获取连续片段作为正样本, 来自不同文档的句段配对作为负样本, 正样本和负样本均以相同的概率(0.5)采样.

直接使用预训练模型中 NSP 任务层的输出, 切分的效果大概率不会很好. 可以构建自己的 NSP 任务继续训练, 例如负样本的采样不再从语料库中不同的文档之间采样, 而是在同一个文档, 不同的段落中采样, 或者按照自己业务的特点设计采样方法. 使用重新采样的正负样本进行 NSP 任务的继续训练, 来满足切分的需要.
