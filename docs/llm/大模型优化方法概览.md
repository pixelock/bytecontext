# 速度优化

## 模型结构优化

### MQA 和 GQA

Multi Query Attention / Group Query Attention 的思路: SRAM GPU显存太小太贵, DRAM GPU显存读取到计算芯片和SRAM 到计算芯片的速度, 差了一个量级的, 这会让计算芯片一直在等待. **减少从内存中读取的数据量, 也就减少了计算单元等待时间, 提高了计算利用率**.

结合KV Cache机制, 使得KV Cache占用的显存变少了, 腾出空间可以用来加大batch size, 又可以提高计算的利用率.

- [为什么现在大家都在用 MQA 和 GQA？](https://mp.weixin.qq.com/s/nl5oIGNchxapgRNRlh2sPA)

---

## 训练专门优化

## 推理专门优化

---

# 显存优化

## 推理专门优化

### MQA 和 GQA

见上面相同章节.

---

# 上下文长度扩展

## 模型结构

### FlashAttention

**FlashAttention主要解决Transformer计算速度慢和存储占用高的问题**. **FlashAttention将优化重点放在了降低存储访问开销(Memory Access Cost, MAC)**. **FlashAttention的目标是降低MAC, 即使代价是增加了FLOPS.**

尤其是当计算本身已经很高效的情况下, Efficient Transformer虽然能够有效降低模型的FLOPS, 导致MAC的开销更加不能忽略. MAC的开销主要来自两方面:

- 一是从存储中读取数据
- 二是向存储中写数据

为了减少对低速GPU显存的读写, **FlashAttention将参与计算的矩阵进行分块送进SRAM**, 减少了对显存读写, 来提高整体读写速度. 通过分块动态更新的方式计算得到与传入全部矩阵等价的结果. 虽然增加了额外的计算, 但降低MAC带来的时间收益更大, 从而显著提升了整体的计算速度.

- [FlashAttention 的速度优化原理是怎样的？](https://www.zhihu.com/question/611236756/answer/3132304304)
- [FlashAttention图解（如何加速Attention）](https://zhuanlan.zhihu.com/p/626079753)

### FlashAttention2

相比FlashAttention, 优化点主要在:

- 在FlashAttention算法基础上进行了调整, 减少了非矩阵乘法运算的FLOPs. 这是因为现代GPU有针对matmul(GEMM)专用的计算单元(如Nvidia GPU上的Tensor Cores). 以A100 GPU为例, 其FP16/BF16矩阵乘法的最大理论吞吐量为312 TFLOPs/s, 但FP32非矩阵乘法仅有19.5 TFLOPs/s
- FlashAttention在batch和heads两个维度上进行了并行化, 使用一个thread block来处理一个attention head, 总共需要thread block的数量等于batch size × number of heads; FlashAttention2还在**序列长度**这一维度上进行并行化, 使得当batch size和head数量较小时, 同时计算的核心数量仍然较多, 提高GPU占用率

- [FlashAttention2详解（性能比FlashAttention提升200%）](https://zhuanlan.zhihu.com/p/645376942)

---

# 并行

- [DeepSpeed之ZeRO系列：将显存优化进行到底](https://zhuanlan.zhihu.com/p/513571706?utm_id=0)
- [图解大模型训练之：数据并行上篇(DP, DDP与ZeRO)](https://zhuanlan.zhihu.com/p/617133971)
- [图解大模型训练之：数据并行下篇( DeepSpeed ZeRO，零冗余优化)](https://zhuanlan.zhihu.com/p/618865052)
- [图解大模型训练之：张量模型并行(TP)，Megatron-LM](https://zhuanlan.zhihu.com/p/622212228)

---

# TODO

- [Transformer技术总结](https://zhuanlan.zhihu.com/p/634345592)
- [大部分的大模型(LLM)采用左填充(left-padding)的原因](https://zhuanlan.zhihu.com/p/646852375)
